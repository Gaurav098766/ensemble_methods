# -*- coding: utf-8 -*-
"""ensemble

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VjFxKxhj_O3U4xiUR5SVTdGR33uJnAj7
"""

import numpy as np # linear algebra
import pandas as pd # d

df = pd.read_csv("/content/sample_data/iris.csv")

df.head



from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

df['species'] = encoder.fit_transform(df['species'])

df.head()

import seaborn as sns
sns.pairplot(df,hue='species')

new_df = df[df['species'] != 0][['sepal_length','sepal_width','species']]

new_df.head()

new_df.shape

X=df.iloc[:,0:2]
Y=df.iloc[:,-1]

X

Y

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

c1f1 = LogisticRegression()
c1f2 = RandomForestClassifier()
c1f3 = KNeighborsClassifier()

estimators = [('lr' , c1f1),('rf',c1f2) , ('knn',c1f3)]

for estimator in estimators:
  x = cross_val_score(estimator[1], X , Y , cv = 10,scoring='accuracy')
  print(estimator[0], np.round(np.mean(x), 2))

from sklearn.ensemble import VotingClassifier

vc = VotingClassifier(estimators = estimators,voting = 'hard')
x = cross_val_score(vc , X,Y,cv = 10,scoring='accuracy')
print(np.round(np.mean(x),2))

vc1 = VotingClassifier(estimators = estimators,voting = 'soft')
x = cross_val_score(vc1 , X,Y,cv = 10,scoring='accuracy')
print(np.round(np.mean(x),2))

for i in range(1,4):
  for j in range(1,4):
    for k in range(1,4):
      vc = VotingClassifier(estimators = estimators,voting = 'soft', weights = [i,j,k])
      x = cross_val_score(vc , X,Y,cv = 10,scoring='accuracy')
      print("for i = {} , j = {}, k= {}".format(i,j,k),np.round(np.mean(x), 2))